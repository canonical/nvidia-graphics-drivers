diff --git a/common/inc/nv-linux.h b/common/inc/nv-linux.h
index 7eba67ee..e9294c88 100644
--- a/common/inc/nv-linux.h
+++ b/common/inc/nv-linux.h
@@ -1968,4 +1968,17 @@ static inline NvU32 nv_default_irq_flags(nv_state_t *nv)
 
 NvS32 nv_request_soc_irq(nv_linux_state_t *, NvU32, nv_soc_irq_type_t, NvU32, NvU32);
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 3, 0)
+// Rel. commit "mm: introduce vma->vm_flags wrapper functions" (Suren Baghdasaryan, 26 Jan 2023)
+static inline void vm_flags_set(struct vm_area_struct *vma, vm_flags_t flags)
+{
+    vma->vm_flags |= flags;
+}
+
+static inline void vm_flags_clear(struct vm_area_struct *vma, vm_flags_t flags)
+{
+    vma->vm_flags &= ~flags;
+}
+#endif
+
 #endif  /* _NV_LINUX_H_ */
diff --git a/nvidia-drm/nvidia-drm-gem-user-memory.c b/nvidia-drm/nvidia-drm-gem-user-memory.c
index 42294590..aeb36c72 100644
--- a/nvidia-drm/nvidia-drm-gem-user-memory.c
+++ b/nvidia-drm/nvidia-drm-gem-user-memory.c
@@ -95,9 +95,9 @@ static bool __nv_drm_gem_user_memory_adjust_mmap_flags(
         return false;
     }
 
-    vma->vm_flags &= ~VM_PFNMAP;
-    vma->vm_flags &= ~VM_IO;
-    vma->vm_flags |= VM_MIXEDMAP;
+    vm_flags_clear(vma, VM_PFNMAP);
+    vm_flags_clear(vma, VM_IO);
+    vm_flags_set(vma, VM_MIXEDMAP);
 
     return true;
 }
diff --git a/nvidia-uvm/uvm8.c b/nvidia-uvm/uvm8.c
index 14289f83..1bce3555 100644
--- a/nvidia-uvm/uvm8.c
+++ b/nvidia-uvm/uvm8.c
@@ -812,7 +812,7 @@ static int uvm_mmap(struct file *filp, struct vm_area_struct *vma)
     // Using VM_DONTCOPY would be nice, but madvise(MADV_DOFORK) can reset that
     // so we have to handle vm_open on fork anyway. We could disable MADV_DOFORK
     // with VM_IO, but that causes other mapping issues.
-    vma->vm_flags |= VM_MIXEDMAP | VM_DONTEXPAND;
+    vm_flags_set(vma, VM_MIXEDMAP | VM_DONTEXPAND);
 
     vma->vm_ops = &uvm_vm_ops_managed;
 
diff --git a/nvidia/nv-mmap.c b/nvidia/nv-mmap.c
index 0dc23963..d1746b06 100644
--- a/nvidia/nv-mmap.c
+++ b/nvidia/nv-mmap.c
@@ -450,7 +450,7 @@ static int nvidia_mmap_numa(
     }
 
     // Needed for the linux kernel for mapping compound pages
-    vma->vm_flags |= VM_MIXEDMAP;
+    vm_flags_set(vma, VM_MIXEDMAP);
 
     for (i = 0, addr = mmap_context->page_array[0]; i < pages;
          addr = mmap_context->page_array[++i], start += PAGE_SIZE)
@@ -599,7 +599,7 @@ int nvidia_mmap_helper(
         }
         up(&nvl->mmap_lock);
 
-        vma->vm_flags |= VM_IO | VM_PFNMAP | VM_DONTEXPAND;
+	vm_flags_set(vma, VM_IO | VM_PFNMAP | VM_DONTEXPAND);
     }
     else
     {
@@ -666,15 +666,15 @@ int nvidia_mmap_helper(
 
         NV_PRINT_AT(NV_DBG_MEMINFO, at);
 
-        vma->vm_flags |= (VM_IO | VM_LOCKED | VM_RESERVED);
-        vma->vm_flags |= (VM_DONTEXPAND | VM_DONTDUMP);
+        vm_flags_set(vma, VM_IO | VM_LOCKED | VM_RESERVED);
+        vm_flags_set(vma, VM_DONTEXPAND | VM_DONTDUMP);
     }
 
     if ((prot & NV_PROTECT_WRITEABLE) == 0)
     {
         vma->vm_page_prot = NV_PGPROT_READ_ONLY(vma->vm_page_prot);
-        vma->vm_flags &= ~VM_WRITE;
-        vma->vm_flags &= ~VM_MAYWRITE;
+        vm_flags_clear(vma, VM_WRITE);
+        vm_flags_clear(vma, VM_MAYWRITE);
     }
 
     vma->vm_ops = &nv_vm_ops;
